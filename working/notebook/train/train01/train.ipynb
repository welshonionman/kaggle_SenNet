{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-07T01:52:38.718744Z",
     "iopub.status.busy": "2024-01-07T01:52:38.718608Z",
     "iopub.status.idle": "2024-01-07T01:52:42.586686Z",
     "shell.execute_reply": "2024-01-07T01:52:42.586096Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "from src.model.model import save_model, load_inference_model\n",
    "from src.dataset.df import check_dataset\n",
    "from src.utils.common import set_seed\n",
    "\n",
    "from src.experiment.inference import inference\n",
    "from src.experiment.initialize import init_exp\n",
    "from src.utils.metrics import compute_surface_dice_score_from_volume\n",
    "from src.model.model import build_model\n",
    "from src.model.loss import get_lossfn\n",
    "from src.utils.metrics import get_metrics\n",
    "from src.model.scheduler import get_scheduler\n",
    "from src.dataset.common import get_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T01:52:42.589433Z",
     "iopub.status.busy": "2024-01-07T01:52:42.589032Z",
     "iopub.status.idle": "2024-01-07T01:52:42.610525Z",
     "shell.execute_reply": "2024-01-07T01:52:42.609985Z"
    }
   },
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    debug = False\n",
    "    check_dataset = False\n",
    "\n",
    "    # = data CFG ====================================================\n",
    "\n",
    "    dataset_path = \"/kaggle/working/dataset/train01_xy_256_128_z_1_2/\"\n",
    "    train_dataset = \"Base2dDataset\"\n",
    "    negative_sample_rate = 0.2\n",
    "\n",
    "    # = experiment CFG =================================================\n",
    "\n",
    "    project = \"SenNet\"\n",
    "    exp_name = os.path.basename(os.getcwd())\n",
    "    notes = \"preliminary model\"\n",
    "\n",
    "    # = model CFG ======================================================\n",
    "\n",
    "    model_arch = \"Unet\"\n",
    "    backbone = \"se_resnext50_32x4d\"\n",
    "    in_chans = 1\n",
    "    target_size = 1\n",
    "\n",
    "    # = training CFG ===================================================\n",
    "\n",
    "    epochs = 60\n",
    "\n",
    "    train_batch_size = 64\n",
    "    valid_batch_size = train_batch_size\n",
    "\n",
    "    loss = \"DiceLoss\"\n",
    "    metrics = \"Dice\"\n",
    "    lr = 5e-4\n",
    "    num_workers = 12\n",
    "\n",
    "    # = augmentation ===================================================\n",
    "\n",
    "    image_size = 256\n",
    "    train_aug = [\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.RandomGamma(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.ShiftScaleRotate(p=0.5),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    valid_aug = [\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    # =============== inference ========================================\n",
    "\n",
    "    test_dataset = \"BaseInferenceDataset\"\n",
    "    stride = image_size // 2\n",
    "    drop_egde_pixel = 32\n",
    "\n",
    "\n",
    "load_dotenv(\"/kaggle/key.env\")\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T01:52:42.612743Z",
     "iopub.status.busy": "2024-01-07T01:52:42.612486Z",
     "iopub.status.idle": "2024-01-07T01:52:51.138112Z",
     "shell.execute_reply": "2024-01-07T01:52:51.137629Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\welsh\\AppData\\Local\\Temp\\ipykernel_10256\\4046888049.py:10: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{cfg.dataset_path}/dataset.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>fname</th>\n",
       "      <th>kidney</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>fold0</th>\n",
       "      <th>fold1</th>\n",
       "      <th>fold2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x0_y0_z0_std0039_sum0</td>\n",
       "      <td>kidney_1_dense</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x0_y0_z100_std0037_sum0</td>\n",
       "      <td>kidney_1_dense</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x0_y0_z102_std0036_sum0</td>\n",
       "      <td>kidney_1_dense</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x0_y0_z104_std0036_sum0</td>\n",
       "      <td>kidney_1_dense</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x0_y0_z106_std0036_sum0</td>\n",
       "      <td>kidney_1_dense</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481727</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x896_y256_z990_std0261_sum1352</td>\n",
       "      <td>kidney_3_sparse</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>990</td>\n",
       "      <td>261</td>\n",
       "      <td>1352</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481728</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x896_y256_z992_std0262_sum1473</td>\n",
       "      <td>kidney_3_sparse</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>992</td>\n",
       "      <td>262</td>\n",
       "      <td>1473</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481729</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x896_y256_z994_std0263_sum1554</td>\n",
       "      <td>kidney_3_sparse</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>994</td>\n",
       "      <td>263</td>\n",
       "      <td>1554</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481730</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x896_y256_z996_std0264_sum1656</td>\n",
       "      <td>kidney_3_sparse</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>996</td>\n",
       "      <td>264</td>\n",
       "      <td>1656</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481731</th>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>/kaggle/working/dataset/cropped_xy_256_128_z_1...</td>\n",
       "      <td>x896_y256_z998_std0265_sum1830</td>\n",
       "      <td>kidney_3_sparse</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>998</td>\n",
       "      <td>265</td>\n",
       "      <td>1830</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481732 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_path  \\\n",
       "0       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "1       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "2       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "3       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "4       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "...                                                   ...   \n",
       "481727  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481728  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481729  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481730  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481731  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "\n",
       "                                               label_path  \\\n",
       "0       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "1       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "2       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "3       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "4       /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "...                                                   ...   \n",
       "481727  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481728  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481729  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481730  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "481731  /kaggle/working/dataset/cropped_xy_256_128_z_1...   \n",
       "\n",
       "                                 fname           kidney    x    y    z  std  \\\n",
       "0                x0_y0_z0_std0039_sum0   kidney_1_dense    0    0    0   39   \n",
       "1              x0_y0_z100_std0037_sum0   kidney_1_dense    0    0  100   37   \n",
       "2              x0_y0_z102_std0036_sum0   kidney_1_dense    0    0  102   36   \n",
       "3              x0_y0_z104_std0036_sum0   kidney_1_dense    0    0  104   36   \n",
       "4              x0_y0_z106_std0036_sum0   kidney_1_dense    0    0  106   36   \n",
       "...                                ...              ...  ...  ...  ...  ...   \n",
       "481727  x896_y256_z990_std0261_sum1352  kidney_3_sparse  896  256  990  261   \n",
       "481728  x896_y256_z992_std0262_sum1473  kidney_3_sparse  896  256  992  262   \n",
       "481729  x896_y256_z994_std0263_sum1554  kidney_3_sparse  896  256  994  263   \n",
       "481730  x896_y256_z996_std0264_sum1656  kidney_3_sparse  896  256  996  264   \n",
       "481731  x896_y256_z998_std0265_sum1830  kidney_3_sparse  896  256  998  265   \n",
       "\n",
       "         sum  fold0  fold1  fold2  \n",
       "0          0  valid  train  train  \n",
       "1          0  valid  train  train  \n",
       "2          0  valid  train  train  \n",
       "3          0  valid  train  train  \n",
       "4          0  valid  train  train  \n",
       "...      ...    ...    ...    ...  \n",
       "481727  1352  train    NaN    NaN  \n",
       "481728  1473  train    NaN    NaN  \n",
       "481729  1554  train    NaN    NaN  \n",
       "481730  1656  train    NaN    NaN  \n",
       "481731  1830  train    NaN    NaN  \n",
       "\n",
       "[481732 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_dataset(df):\n",
    "    # trainのうちlabelが全くないものは90%の確率で除外\n",
    "    df[\"random\"] = np.random.rand(len(df))\n",
    "    df = df[(df[\"sum\"] > 0) | (df[\"fold0\"] == \"valid\") | (df[\"random\"] < cfg.negative_sample_rate)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop([\"random\"], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{cfg.dataset_path}/dataset.csv\")\n",
    "df = filter_dataset(df)\n",
    "# df = df.sample(1000).reset_index(drop=True)\n",
    "if cfg.debug:\n",
    "    df = df.sample(10000).reset_index(drop=True)\n",
    "display(df)\n",
    "\n",
    "if cfg.check_dataset:\n",
    "    check_dataset(df, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T01:52:51.157425Z",
     "iopub.status.busy": "2024-01-07T01:52:51.157197Z",
     "iopub.status.idle": "2024-01-07T12:46:21.995347Z",
     "shell.execute_reply": "2024-01-07T12:46:21.993525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_arch:  Unet\n",
      "backbone:  se_resnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwelshonionman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle\\wandb\\run-20240120_211358-mt07lrv3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/welshonionman/SenNet/runs/mt07lrv3' target=\"_blank\">train01_fold2</a></strong> to <a href='https://wandb.ai/welshonionman/SenNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/welshonionman/SenNet' target=\"_blank\">https://wandb.ai/welshonionman/SenNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/welshonionman/SenNet/runs/mt07lrv3' target=\"_blank\">https://wandb.ai/welshonionman/SenNet/runs/mt07lrv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/60  Mem : 8.95GB  LR : 5.00E-04  Loss: 0.1188: 100%|██████████| 4352/4352 [13:36<00:00,  5.33it/s]\n",
      "Val Loss: 0.2281: 100%|██████████| 2503/2503 [04:37<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.2281\tSAVED MODEL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60  Mem : 9.95GB  LR : 5.00E-03  Loss: 0.1245: 100%|██████████| 4352/4352 [13:13<00:00,  5.48it/s]\n",
      "Val Loss: 0.2013: 100%|██████████| 2503/2503 [04:34<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.2013\tSAVED MODEL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60  Mem : 9.95GB  LR : 5.00E-04  Loss: 0.0789: 100%|██████████| 4352/4352 [13:14<00:00,  5.48it/s]\n",
      "Val Loss: 0.1652: 100%|██████████| 2503/2503 [04:35<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1652\tSAVED MODEL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60  Mem : 9.95GB  LR : 5.00E-04  Loss: 0.0735: 100%|██████████| 4352/4352 [13:15<00:00,  5.47it/s]\n",
      "Val Loss: 0.1678: 100%|██████████| 2503/2503 [04:35<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60  Mem : 9.95GB  LR : 4.99E-04  Loss: 0.0706: 100%|██████████| 4352/4352 [13:17<00:00,  5.46it/s]\n",
      "Val Loss: 0.1621: 100%|██████████| 2503/2503 [04:36<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1621\tSAVED MODEL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60  Mem : 9.95GB  LR : 4.97E-04  Loss: 0.0692: 100%|██████████| 4352/4352 [13:13<00:00,  5.49it/s]\n",
      "Val Loss: 0.1737: 100%|██████████| 2503/2503 [04:36<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1737\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60  Mem : 9.95GB  LR : 4.95E-04  Loss: 0.0678: 100%|██████████| 4352/4352 [13:15<00:00,  5.47it/s]\n",
      "Val Loss: 0.1574: 100%|██████████| 2503/2503 [04:34<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1574\tSAVED MODEL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60  Mem : 9.95GB  LR : 4.91E-04  Loss: 0.0673: 100%|██████████| 4352/4352 [13:16<00:00,  5.46it/s]\n",
      "Val Loss: 0.1561: 100%|██████████| 2503/2503 [04:35<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1561\tSAVED MODEL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60  Mem : 9.95GB  LR : 4.88E-04  Loss: 0.0666: 100%|██████████| 4352/4352 [13:32<00:00,  5.36it/s]\n",
      "Val Loss: 0.1633: 100%|██████████| 2503/2503 [04:33<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60  Mem : 9.95GB  LR : 4.83E-04  Loss: 0.0657: 100%|██████████| 4352/4352 [13:11<00:00,  5.50it/s]\n",
      "Val Loss: 0.1672: 100%|██████████| 2503/2503 [04:33<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60  Mem : 9.95GB  LR : 4.78E-04  Loss: 0.0654: 100%|██████████| 4352/4352 [13:10<00:00,  5.50it/s]\n",
      "Val Loss: 0.1621: 100%|██████████| 2503/2503 [04:50<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60  Mem : 9.95GB  LR : 4.73E-04  Loss: 0.0648: 100%|██████████| 4352/4352 [14:11<00:00,  5.11it/s]\n",
      "Val Loss: 0.1610: 100%|██████████| 2503/2503 [05:08<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60  Mem : 9.95GB  LR : 4.67E-04  Loss: 0.0639: 100%|██████████| 4352/4352 [14:13<00:00,  5.10it/s]\n",
      "Val Loss: 0.1710: 100%|██████████| 2503/2503 [04:29<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60  Mem : 9.95GB  LR : 4.60E-04  Loss: 0.0639: 100%|██████████| 4352/4352 [12:59<00:00,  5.58it/s]\n",
      "Val Loss: 0.1710: 100%|██████████| 2503/2503 [04:26<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60  Mem : 9.95GB  LR : 4.52E-04  Loss: 0.0631: 100%|██████████| 4352/4352 [12:15<00:00,  5.92it/s]\n",
      "Val Loss: 0.1508: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1508\tSAVED MODEL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60  Mem : 9.95GB  LR : 4.44E-04  Loss: 0.0628: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1557: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1557\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60  Mem : 9.95GB  LR : 4.36E-04  Loss: 0.0625: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1652: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60  Mem : 9.95GB  LR : 4.27E-04  Loss: 0.0622: 100%|██████████| 4352/4352 [12:08<00:00,  5.97it/s]\n",
      "Val Loss: 0.1563: 100%|██████████| 2503/2503 [04:08<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60  Mem : 9.95GB  LR : 4.17E-04  Loss: 0.0623: 100%|██████████| 4352/4352 [12:10<00:00,  5.96it/s]\n",
      "Val Loss: 0.1656: 100%|██████████| 2503/2503 [04:08<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60  Mem : 9.95GB  LR : 4.07E-04  Loss: 0.0616: 100%|██████████| 4352/4352 [12:06<00:00,  5.99it/s]\n",
      "Val Loss: 0.1688: 100%|██████████| 2503/2503 [04:09<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1688\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/60  Mem : 9.95GB  LR : 3.97E-04  Loss: 0.0613: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1793: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/60  Mem : 9.95GB  LR : 3.86E-04  Loss: 0.0610: 100%|██████████| 4352/4352 [12:04<00:00,  6.00it/s]\n",
      "Val Loss: 0.1796: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1796\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/60  Mem : 9.95GB  LR : 3.75E-04  Loss: 0.0607: 100%|██████████| 4352/4352 [12:08<00:00,  5.97it/s]\n",
      "Val Loss: 0.1539: 100%|██████████| 2503/2503 [04:08<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1539\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/60  Mem : 9.95GB  LR : 3.64E-04  Loss: 0.0602: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1630: 100%|██████████| 2503/2503 [04:08<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/60  Mem : 9.95GB  LR : 3.52E-04  Loss: 0.0601: 100%|██████████| 4352/4352 [12:10<00:00,  5.96it/s]\n",
      "Val Loss: 0.1663: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/60  Mem : 9.95GB  LR : 3.40E-04  Loss: 0.0600: 100%|██████████| 4352/4352 [12:05<00:00,  6.00it/s]\n",
      "Val Loss: 0.1625: 100%|██████████| 2503/2503 [04:09<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/60  Mem : 9.95GB  LR : 3.27E-04  Loss: 0.0596: 100%|██████████| 4352/4352 [12:16<00:00,  5.91it/s]\n",
      "Val Loss: 0.1675: 100%|██████████| 2503/2503 [04:08<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1675\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/60  Mem : 9.95GB  LR : 3.15E-04  Loss: 0.0590: 100%|██████████| 4352/4352 [12:16<00:00,  5.91it/s]\n",
      "Val Loss: 0.1773: 100%|██████████| 2503/2503 [04:09<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/60  Mem : 9.95GB  LR : 3.02E-04  Loss: 0.0590: 100%|██████████| 4352/4352 [12:14<00:00,  5.92it/s]\n",
      "Val Loss: 0.1924: 100%|██████████| 2503/2503 [04:08<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/60  Mem : 9.95GB  LR : 2.89E-04  Loss: 0.0588: 100%|██████████| 4352/4352 [12:15<00:00,  5.92it/s]\n",
      "Val Loss: 0.1580: 100%|██████████| 2503/2503 [04:08<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/60  Mem : 9.95GB  LR : 2.76E-04  Loss: 0.0584: 100%|██████████| 4352/4352 [12:17<00:00,  5.90it/s]\n",
      "Val Loss: 0.1633: 100%|██████████| 2503/2503 [04:09<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/60  Mem : 9.95GB  LR : 2.63E-04  Loss: 0.0584: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1743: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1743\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/60  Mem : 9.95GB  LR : 2.50E-04  Loss: 0.0578: 100%|██████████| 4352/4352 [12:20<00:00,  5.88it/s]\n",
      "Val Loss: 0.1593: 100%|██████████| 2503/2503 [04:09<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/60  Mem : 9.95GB  LR : 2.37E-04  Loss: 0.0579: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1516: 100%|██████████| 2503/2503 [04:09<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/60  Mem : 9.95GB  LR : 2.24E-04  Loss: 0.0573: 100%|██████████| 4352/4352 [12:20<00:00,  5.87it/s]\n",
      "Val Loss: 0.1656: 100%|██████████| 2503/2503 [04:05<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/60  Mem : 9.95GB  LR : 2.11E-04  Loss: 0.0570: 100%|██████████| 4352/4352 [12:20<00:00,  5.88it/s]\n",
      "Val Loss: 0.1721: 100%|██████████| 2503/2503 [04:06<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/60  Mem : 9.95GB  LR : 1.98E-04  Loss: 0.0566: 100%|██████████| 4352/4352 [12:23<00:00,  5.85it/s]\n",
      "Val Loss: 0.1545: 100%|██████████| 2503/2503 [04:06<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/60  Mem : 9.95GB  LR : 1.85E-04  Loss: 0.0565: 100%|██████████| 4352/4352 [12:20<00:00,  5.88it/s]\n",
      "Val Loss: 0.1575: 100%|██████████| 2503/2503 [04:06<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/60  Mem : 9.95GB  LR : 1.73E-04  Loss: 0.0560: 100%|██████████| 4352/4352 [12:18<00:00,  5.89it/s]\n",
      "Val Loss: 0.1733: 100%|██████████| 2503/2503 [04:06<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/60  Mem : 9.95GB  LR : 1.60E-04  Loss: 0.0560: 100%|██████████| 4352/4352 [12:23<00:00,  5.86it/s]\n",
      "Val Loss: 0.1682: 100%|██████████| 2503/2503 [04:06<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/60  Mem : 9.95GB  LR : 1.48E-04  Loss: 0.0557: 100%|██████████| 4352/4352 [12:21<00:00,  5.87it/s]\n",
      "Val Loss: 0.1723: 100%|██████████| 2503/2503 [04:05<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1723\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/60  Mem : 9.95GB  LR : 1.37E-04  Loss: 0.0555: 100%|██████████| 4352/4352 [12:26<00:00,  5.83it/s]\n",
      "Val Loss: 0.1784: 100%|██████████| 2503/2503 [04:06<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/60  Mem : 9.95GB  LR : 1.25E-04  Loss: 0.0553: 100%|██████████| 4352/4352 [12:28<00:00,  5.81it/s]\n",
      "Val Loss: 0.1732: 100%|██████████| 2503/2503 [04:06<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/60  Mem : 9.95GB  LR : 1.14E-04  Loss: 0.0553: 100%|██████████| 4352/4352 [12:23<00:00,  5.85it/s]\n",
      "Val Loss: 0.1657: 100%|██████████| 2503/2503 [04:14<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/60  Mem : 9.95GB  LR : 1.03E-04  Loss: 0.0549: 100%|██████████| 4352/4352 [13:38<00:00,  5.32it/s]\n",
      "Val Loss: 0.1685: 100%|██████████| 2503/2503 [04:14<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/60  Mem : 9.95GB  LR : 9.28E-05  Loss: 0.0549: 100%|██████████| 4352/4352 [13:25<00:00,  5.40it/s]\n",
      "Val Loss: 0.1617: 100%|██████████| 2503/2503 [04:14<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/60  Mem : 9.95GB  LR : 8.28E-05  Loss: 0.0546: 100%|██████████| 4352/4352 [13:28<00:00,  5.38it/s]\n",
      "Val Loss: 0.1668: 100%|██████████| 2503/2503 [04:17<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/60  Mem : 9.95GB  LR : 7.33E-05  Loss: 0.0541: 100%|██████████| 4352/4352 [12:27<00:00,  5.83it/s]\n",
      "Val Loss: 0.1788: 100%|██████████| 2503/2503 [04:07<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/60  Mem : 9.95GB  LR : 6.43E-05  Loss: 0.0541: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1718: 100%|██████████| 2503/2503 [04:07<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/60  Mem : 9.95GB  LR : 5.58E-05  Loss: 0.0541: 100%|██████████| 4352/4352 [12:11<00:00,  5.95it/s]\n",
      "Val Loss: 0.1732: 100%|██████████| 2503/2503 [04:07<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/60  Mem : 9.95GB  LR : 4.78E-05  Loss: 0.0539: 100%|██████████| 4352/4352 [12:05<00:00,  6.00it/s]\n",
      "Val Loss: 0.1755: 100%|██████████| 2503/2503 [04:08<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/60  Mem : 9.95GB  LR : 4.04E-05  Loss: 0.0538: 100%|██████████| 4352/4352 [12:28<00:00,  5.81it/s]\n",
      "Val Loss: 0.1776: 100%|██████████| 2503/2503 [04:08<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/60  Mem : 9.95GB  LR : 3.36E-05  Loss: 0.0536: 100%|██████████| 4352/4352 [12:16<00:00,  5.91it/s]\n",
      "Val Loss: 0.1832: 100%|██████████| 2503/2503 [04:20<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/60  Mem : 9.95GB  LR : 2.73E-05  Loss: 0.0536: 100%|██████████| 4352/4352 [13:28<00:00,  5.38it/s]\n",
      "Val Loss: 0.1747: 100%|██████████| 2503/2503 [04:13<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/60  Mem : 9.95GB  LR : 2.17E-05  Loss: 0.0533: 100%|██████████| 4352/4352 [13:22<00:00,  5.43it/s]\n",
      "Val Loss: 0.1799: 100%|██████████| 2503/2503 [04:14<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1799\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/60  Mem : 9.95GB  LR : 1.67E-05  Loss: 0.0532: 100%|██████████| 4352/4352 [13:39<00:00,  5.31it/s]\n",
      "Val Loss: 0.1793: 100%|██████████| 2503/2503 [04:26<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/60  Mem : 9.95GB  LR : 1.23E-05  Loss: 0.0533: 100%|██████████| 4352/4352 [13:49<00:00,  5.25it/s]\n",
      "Val Loss: 0.1764: 100%|██████████| 2503/2503 [04:26<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/60  Mem : 9.95GB  LR : 8.62E-06  Loss: 0.0530: 100%|██████████| 4352/4352 [13:19<00:00,  5.45it/s]\n",
      "Val Loss: 0.1815: 100%|██████████| 2503/2503 [04:06<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/60  Mem : 9.95GB  LR : 5.56E-06  Loss: 0.0530: 100%|██████████| 4352/4352 [13:10<00:00,  5.50it/s]\n",
      "Val Loss: 0.1788: 100%|██████████| 2503/2503 [04:06<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/60  Mem : 9.95GB  LR : 3.18E-06  Loss: 0.0530: 100%|██████████| 4352/4352 [13:11<00:00,  5.50it/s]\n",
      "Val Loss: 0.1761: 100%|██████████| 2503/2503 [04:07<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.1761\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8244eb510fc14a4da6c7a62dcfab1c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>▇█▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▆▂▂▂▁▂▂▃▃▁▂▂▃▄▁▂▂▃▅▂▃▁▂▁▂▃▃▃▂▂▂▃▃▃▄▄▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>59</td></tr><tr><td>train_loss</td><td>0.05297</td></tr><tr><td>valid_loss</td><td>0.17611</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train01_fold2</strong> at: <a href='https://wandb.ai/welshonionman/SenNet/runs/mt07lrv3' target=\"_blank\">https://wandb.ai/welshonionman/SenNet/runs/mt07lrv3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/kaggle\\wandb\\run-20240120_211358-mt07lrv3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if cfg.debug:\n",
    "    print(\"!!!Debug mode!!!\\n\")\n",
    "    cfg.epochs = 5\n",
    "\n",
    "for fold in [2]:\n",
    "    dataset = get_train_dataset(cfg)\n",
    "\n",
    "    train_df = df[df[f\"fold{fold}\"] == \"train\"]\n",
    "    valid_df = df[df[f\"fold{fold}\"] == \"valid\"]\n",
    "\n",
    "    train_dataset = dataset(train_df, cfg, is_train=True)\n",
    "    valid_dataset = dataset(valid_df, cfg, is_train=False)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=cfg.train_batch_size, num_workers=cfg.num_workers, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=cfg.valid_batch_size, num_workers=cfg.num_workers, shuffle=False)\n",
    "\n",
    "    model = build_model(cfg.model_arch, cfg.backbone, cfg.in_chans, cfg.target_size)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    criterion = get_lossfn(cfg)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr)\n",
    "    scheduler = get_scheduler(cfg, optimizer)\n",
    "    metrics = get_metrics(cfg)\n",
    "\n",
    "    # model, scaler, criterion, optimizer, scheduler, metrics = init_model(cfg)\n",
    "    slacknotify = init_exp(fold, cfg)\n",
    "\n",
    "    path_best = f\"./{cfg.exp_name}/{cfg.exp_name}_best_fold{fold}.pth\"\n",
    "    path_last = f\"./{cfg.exp_name}/{cfg.exp_name}_last_fold{fold}.pth\"\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        pbar_train = tqdm(enumerate(train_dataloader), total=len(train_dataloader), bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-0b}\")\n",
    "\n",
    "        for i, (images, masks) in pbar_train:\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with amp.autocast():\n",
    "                preds = model(images)\n",
    "                loss = criterion(preds, masks)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                total_loss += loss.detach().item()\n",
    "\n",
    "            loss_ = total_loss / (i + 1)\n",
    "            lr = f\"LR : {scheduler.get_lr()[0]:.2E}\"\n",
    "            gpu_mem = f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\"\n",
    "            pbar_train.set_description((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{cfg.epochs}\", gpu_mem, lr, f\"Loss: {loss_:.4f}\"))\n",
    "\n",
    "        train_loss = loss_\n",
    "        scheduler.step()\n",
    "        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss})\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        pbar_val = tqdm(enumerate(valid_dataloader), total=len(valid_dataloader), bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "\n",
    "        for i, (images, masks) in pbar_val:\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "            with torch.no_grad():\n",
    "                preds = model(images)\n",
    "                loss = criterion(preds, masks)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            loss_ = total_loss / (i + 1)\n",
    "            pbar_val.set_description((\"%10s\") % (f\"Val Loss: {loss_:.4f}\"))\n",
    "        valid_loss = loss_\n",
    "        wandb.log({\"epoch\": epoch, \"valid_loss\": valid_loss})\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            print(f\"loss : {valid_loss:.4f}\\tSAVED MODEL\\n\")\n",
    "            slacknotify.send_reply(f\"epoch : {epoch}\\tscore : {valid_loss:.4f}\\tBEST\")\n",
    "            best_loss = valid_loss\n",
    "            save_model(model, cfg, path_best, loss=loss)\n",
    "        else:\n",
    "            print(f\"loss : {valid_loss:.4f}\\n\")\n",
    "            slacknotify.send_reply(f\"epoch : {epoch}\\tscore : {valid_loss:.4f}\")\n",
    "\n",
    "    save_model(model, cfg, path_last, loss=valid_loss)\n",
    "    wandb.config.update({\"last_loss\": valid_loss, \"best_loss\": best_loss})\n",
    "\n",
    "    slacknotify.send_reply(f\"{cfg.exp_name}_fold{fold} training finished\\nbest loss : {best_loss:.4f} last loss : {loss_:.4f}\", True)\n",
    "\n",
    "    if wandb.run:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name Unet\n",
      "backbone se_resnext50_32x4d\n",
      "fold_2\n",
      "kidney_2_sparse\n",
      "/kaggle/working/dataset/stack_clipped/kidney_2_sparse_images.npy\n",
      "(0.67, 0.8495)\n"
     ]
    }
   ],
   "source": [
    "# valid\n",
    "fold_dict = json.load(open(\"/kaggle/src/dataset/fold.json\", \"r\"))\n",
    "pth_type = \"best\"\n",
    "\n",
    "for fold in [2]:\n",
    "    kidney = fold_dict[f\"fold{fold}\"][\"valid\"][0]\n",
    "    pth_path = f\"./{cfg.exp_name}/{cfg.exp_name}_{pth_type}_fold{fold}.pth\"\n",
    "    stack_path = f\"/kaggle/working/dataset/stack_train01/{kidney}_images.npy\"\n",
    "    label_path = f\"/kaggle/working/dataset/stack_train01/{kidney}_labels.npy\"\n",
    "    preds_path = f\"./preds/{kidney}_{pth_type}_preds.npy\"\n",
    "\n",
    "    model = load_inference_model(pth_path, cfg)\n",
    "\n",
    "    print(kidney)\n",
    "    print(stack_path)\n",
    "    # inference(model, stack_path, preds_path, cfg)\n",
    "\n",
    "    label = np.load(label_path)\n",
    "    preds = np.load(preds_path)\n",
    "    thresh_score_dict = {}\n",
    "\n",
    "    for thresh in np.arange(0.1, 0.99, 0.1):\n",
    "        thresh = round(thresh, 5)\n",
    "        thresh_score_dict[thresh] = compute_surface_dice_score_from_volume(ne.evaluate(\"preds > thresh\"), label)\n",
    "\n",
    "    max_score_thresh = max(thresh_score_dict, key=thresh_score_dict.get)\n",
    "\n",
    "    for thresh in np.arange(max_score_thresh - 0.1, max_score_thresh + 0.1, 0.01):\n",
    "        thresh = round(thresh, 5)\n",
    "        thresh_score_dict[thresh] = compute_surface_dice_score_from_volume(ne.evaluate(\"preds > thresh\"), label)\n",
    "\n",
    "    print(max(thresh_score_dict.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name Unet\n",
      "backbone se_resnext50_32x4d\n",
      "/kaggle/working/dataset/stack_clipped/kidney_2_sparse_images.npy\n",
      "././preds/kidney_2_sparse_preds_0.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2216/2216 [10:13<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././preds/kidney_2_sparse_preds_1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [09:36<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././preds/kidney_2_sparse_preds_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1510/1510 [10:44<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name Unet\n",
      "backbone se_resnext50_32x4d\n",
      "/kaggle/working/dataset/stack_clipped/kidney_3_sparse_images.npy\n",
      "././preds/kidney_3_sparse_preds_0.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [03:35<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././preds/kidney_3_sparse_preds_1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1705/1705 [03:35<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././preds/kidney_3_sparse_preds_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1509/1509 [03:39<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name Unet\n",
      "backbone se_resnext50_32x4d\n",
      "/kaggle/working/dataset/stack_clipped/kidney_9_pseudo_images.npy\n",
      "././preds/kidney_9_pseudo_preds_0.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2140/2140 [10:50<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././preds/kidney_9_pseudo_preds_1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [10:19<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././preds/kidney_9_pseudo_preds_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1643/1643 [10:39<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# infer\n",
    "pth_type = \"best\"\n",
    "fold = 2\n",
    "kidneys = [\"kidney_2_sparse\", \"kidney_3_sparse\", \"kidney_9_pseudo\"]\n",
    "\n",
    "pth_path = f\"./{cfg.exp_name}/{cfg.exp_name}_{pth_type}_fold{fold}.pth\"\n",
    "for kidney in kidneys:\n",
    "    stack_path = f\"/kaggle/working/dataset/stack_train01/{kidney}_images.npy\"\n",
    "    preds_path = f\"./preds/{kidney}_{pth_type}_preds.npy\"\n",
    "\n",
    "    model = load_inference_model(pth_path, cfg)\n",
    "\n",
    "    print(stack_path)\n",
    "    inference(model, stack_path, preds_path, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_type = \"best\"\n",
    "kidneys = [\"kidney_2_sparse\", \"kidney_3_sparse\", \"kidney_9_pseudo\"]\n",
    "for kidney in kidneys:\n",
    "    stack_path = f\"/kaggle/working/dataset/stack_train01/{kidney}_images.npy\"\n",
    "    preds_path = f\"./preds/{kidney}_{pth_type}_preds.npy\"\n",
    "    preds_th_path = f\"./preds/{kidney}_{pth_type}_preds_th.npy\"\n",
    "    preds = np.load(preds_path)\n",
    "    preds_th = (preds > 0.67).astype(np.bool_)\n",
    "    np.save(preds_th_path, preds > 0.67)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    },
    {
     "datasetId": 1074109,
     "sourceId": 1807973,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150248402,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
