{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-27T11:33:05.541375Z","iopub.status.busy":"2023-12-27T11:33:05.540442Z","iopub.status.idle":"2023-12-27T11:33:17.485094Z","shell.execute_reply":"2023-12-27T11:33:17.483939Z","shell.execute_reply.started":"2023-12-27T11:33:05.541338Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","from torch.cuda.amp import autocast\n","import os\n","import segmentation_models_pytorch as smp\n","from torch.utils.data import Dataset, DataLoader\n","import gc"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:17.487395Z","iopub.status.busy":"2023-12-27T11:33:17.487076Z","iopub.status.idle":"2023-12-27T11:33:17.493745Z","shell.execute_reply":"2023-12-27T11:33:17.492854Z","shell.execute_reply.started":"2023-12-27T11:33:17.487366Z"},"trusted":true},"outputs":[],"source":["class cfg:\n","    # ============== model cfg =============\n","    model_name = \"Unet\"\n","    backbone = \"se_resnext50_32x4d\"\n","\n","    in_chans = 6  # 65\n","    # ============== _ cfg =============\n","    image_size = 256\n","    input_size = 256\n","    tile_size = image_size\n","    stride = tile_size // 1\n","    drop_egde_pixel = 32\n","    batch = 64\n","\n","    target_size = 6\n","    chopping_percentile = 1e-3\n","    # ============== fold =============\n","    valid_id = 1\n","    batch = 128\n","    th_percentile = 0.0021\n","    model_path = [\"/kaggle/working/notebook/experiment/baseline/baseline/baseline_best_fold0.pth\"]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:17.495479Z","iopub.status.busy":"2023-12-27T11:33:17.495122Z","iopub.status.idle":"2023-12-27T11:33:17.511174Z","shell.execute_reply":"2023-12-27T11:33:17.510154Z","shell.execute_reply.started":"2023-12-27T11:33:17.495447Z"},"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, model_arch, backbone, in_chans, target_size, weight):\n","        super().__init__()\n","\n","        self.model = smp.create_model(\n","            model_arch,\n","            encoder_name=backbone,\n","            encoder_weights=weight,\n","            in_channels=in_chans,\n","            classes=target_size,\n","            activation=None,\n","        )\n","        self.batch = cfg.batch\n","        self.in_chans = in_chans\n","\n","    def forward_(self, image):\n","        output = self.model(image)\n","        return output[:, 0]\n","\n","    def forward(self, image):\n","        # image.shape=(batch,c,h,w)\n","        image = image.to(torch.float32)\n","\n","        shape = image.shape\n","        image = [torch.rot90(image, k=i, dims=(-2, -1)) for i in range(4)]\n","        image = torch.cat(image, dim=0)\n","        with autocast():\n","            with torch.no_grad():\n","                image = [self.forward_(image[i * self.batch : (i + 1) * self.batch]) for i in range(image.shape[0] // self.batch + 1)]\n","                image = torch.cat(image, dim=0)\n","        image = image.sigmoid()\n","        image = image.reshape(4, shape[0], *shape[2:])\n","        image = [torch.rot90(image[i], k=-i, dims=(-2, -1)) for i in range(4)]\n","        image = torch.stack(image, dim=0).mean(0)\n","\n","        return image\n","\n","\n","def load_model(model_path):\n","    pth = torch.load(model_path)\n","\n","    print(\"model_name\", pth[\"model_arch\"])\n","    print(\"backbone\", pth[\"backbone\"])\n","    model = CustomModel(pth[\"model_arch\"], pth[\"backbone\"], pth[\"in_chans\"], pth[\"target_size\"], weight=None)\n","    model.load_state_dict(pth[\"model\"])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# Functions"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:17.513522Z","iopub.status.busy":"2023-12-27T11:33:17.513262Z","iopub.status.idle":"2023-12-27T11:33:17.540545Z","shell.execute_reply":"2023-12-27T11:33:17.539595Z","shell.execute_reply.started":"2023-12-27T11:33:17.513499Z"},"trusted":true},"outputs":[],"source":["\n","class InferenceDataset(Dataset):\n","    def __init__(self, stack, in_chan):\n","        self.in_chan = in_chan\n","\n","        pad = torch.zeros(self.in_chan // 2, *stack.shape[1:], dtype=stack.dtype)\n","        self.stack = torch.cat((pad, stack, pad), dim=0)\n","\n","    def __len__(self):\n","        return self.stack.shape[0] - self.in_chan\n","\n","    def __getitem__(self, z_):\n","        stack = self.stack[z_ : z_ + self.in_chan]\n","        return stack, z_\n","\n","\n","def add_pad(stack: torch.Tensor, pad: int):\n","    # stack=(C,H,W)\n","    # output=(C,H+2*pad,W+2*pad)\n","    mean_ = int(stack.to(torch.float32).mean())\n","    stack = torch.cat([stack, torch.ones([stack.shape[0], pad, stack.shape[2]], dtype=stack.dtype, device=stack.device) * mean_], dim=1)\n","    stack = torch.cat([stack, torch.ones([stack.shape[0], stack.shape[1], pad], dtype=stack.dtype, device=stack.device) * mean_], dim=2)\n","    stack = torch.cat([torch.ones([stack.shape[0], pad, stack.shape[2]], dtype=stack.dtype, device=stack.device) * mean_, stack], dim=1)\n","    stack = torch.cat([torch.ones([stack.shape[0], stack.shape[1], pad], dtype=stack.dtype, device=stack.device) * mean_, stack], dim=2)\n","    return stack"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def shift_axis(tensor, axis):\n","    perm = [axis, (axis + 1) % 3, (axis + 2) % 3]  # 軸の順番をシフト\n","    tensor = tensor.permute(*perm)\n","    return tensor\n","\n","\n","def remove_pad(pred: torch.Tensor, pad: int):\n","    pred = pred[..., pad:-pad, pad:-pad]\n","    return pred\n","\n","\n","def cutout_chip(img, stack_shape, stride, img_size, edge):\n","    chip = []\n","    xy_indexs = []\n","\n","    x1_list = np.arange(0, stack_shape[-2] + 1, stride)\n","    y1_list = np.arange(0, stack_shape[-1] + 1, stride)\n","\n","    for y1 in y1_list:\n","        for x1 in x1_list:\n","            x2 = x1 + img_size\n","            y2 = y1 + img_size\n","            chip.append(img[..., x1:x2, y1:y2])\n","            xy_indexs.append([x1 + edge, x2 - edge, y1 + edge, y2 - edge])\n","    return chip, xy_indexs"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def infer_postprocess(y_preds, xy_indexs, img_xy):\n","    pred = torch.zeros(img_xy, dtype=torch.float32, device=y_preds.device)\n","    count = torch.zeros(img_xy, dtype=torch.float32, device=y_preds.device)\n","    for i, (x1, x2, y1, y2) in enumerate(xy_indexs):\n","        pred[..., x1:x2, y1:y2] += y_preds[i]\n","        count[..., x1:x2, y1:y2] += 1\n","\n","    pred /= count\n","    return pred"]},{"cell_type":"markdown","metadata":{},"source":["# Build model(s)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:17.541778Z","iopub.status.busy":"2023-12-27T11:33:17.541526Z","iopub.status.idle":"2023-12-27T11:33:18.084421Z","shell.execute_reply":"2023-12-27T11:33:18.083503Z","shell.execute_reply.started":"2023-12-27T11:33:17.541755Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:18.085986Z","iopub.status.busy":"2023-12-27T11:33:18.085673Z","iopub.status.idle":"2023-12-27T11:33:18.106261Z","shell.execute_reply":"2023-12-27T11:33:18.105196Z","shell.execute_reply.started":"2023-12-27T11:33:18.08596Z"},"trusted":true},"outputs":[],"source":["def infer_each_z(model, img, stack_shape):\n","    img = img.to(\"cuda:0\")\n","    img = add_pad(img[0], cfg.tile_size // 2)[None]\n","\n","    chip, xy_indexs = cutout_chip(img, stack_shape, cfg.stride, cfg.tile_size, cfg.drop_egde_pixel)\n","\n","    preds = model.forward(torch.cat(chip)).to(device=0)\n","    preds = remove_pad(preds, cfg.drop_egde_pixel)\n","\n","    pred = torch.zeros_like(img[:, 0], dtype=torch.float32, device=img.device)\n","    count = torch.zeros_like(img[:, 0], dtype=torch.float32, device=img.device)\n","    for i, (x1, x2, y1, y2) in enumerate(xy_indexs):\n","        pred[..., x1:x2, y1:y2] += preds[i]\n","        count[..., x1:x2, y1:y2] += 1\n","    pred /= count\n","    pred = remove_pad(pred, cfg.tile_size // 2)\n","\n","    pred = (pred[0] * 255).to(torch.uint8).cpu()\n","    return pred\n","\n","\n","def get_output(model, stack_path):\n","    os.makedirs(\"/kaggle/working/output\", exist_ok=True)\n","    kidney = stack_path.split(\"/\")[-1].split(\".\")[0]\n","\n","    for axis in [0, 1, 2]:\n","        stack = torch.tensor(np.load(stack_path))\n","        stack = shift_axis(stack, axis)\n","\n","        preds = torch.zeros_like(stack, dtype=torch.uint8)\n","\n","        dataset = InferenceDataset(stack, cfg.in_chans)\n","        dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n","        for img, z_ in tqdm(dataloader):  # img=(1,C,H,W)\n","            # if z_ == 400:\n","            #     break\n","            pred = infer_each_z(model, img, stack.shape)\n","            preds[z_] = pred\n","\n","        preds = shift_axis(preds, -axis)\n","        np.save(f\"/kaggle/working/output/{kidney}_{axis}.npy\", preds)\n","        del stack, preds, dataset, dataloader\n","        gc.collect()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:18.108202Z","iopub.status.busy":"2023-12-27T11:33:18.107531Z","iopub.status.idle":"2023-12-27T11:36:20.192303Z","shell.execute_reply":"2023-12-27T11:36:20.191145Z","shell.execute_reply.started":"2023-12-27T11:33:18.108167Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone efficientnet-b0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2217/2217 [02:53<00:00, 12.76it/s]\n","100%|██████████| 1041/1041 [02:26<00:00,  7.12it/s]\n","100%|██████████| 1511/1511 [03:17<00:00,  7.66it/s]\n"]}],"source":["model = load_model(cfg.model_path[0])\n","get_output(model, \"/kaggle/working/dataset/stack_clipped/kidney_2_images.npy\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["stack_path = \"/kaggle/working/dataset/stack_clipped/kidney_2_images.npy\"\n","stack = torch.tensor(np.load(stack_path))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = InferenceDataset(stack, cfg.in_chans)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def rle_encode(mask):\n","    pixel = mask.flatten()\n","    pixel = np.concatenate([[0], pixel, [0]])\n","    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n","    run[1::2] -= run[::2]\n","    rle = \" \".join(str(r) for r in run)\n","    if rle == \"\":\n","        rle = \"1 0\"\n","    return rle\n","\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":6962461,"sourceId":61446,"sourceType":"competition"},{"datasetId":4087873,"sourceId":7187369,"sourceType":"datasetVersion"},{"sourceId":150248402,"sourceType":"kernelVersion"},{"sourceId":156694315,"sourceType":"kernelVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
