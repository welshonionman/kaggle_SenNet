{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-27T11:33:05.541375Z","iopub.status.busy":"2023-12-27T11:33:05.540442Z","iopub.status.idle":"2023-12-27T11:33:17.485094Z","shell.execute_reply":"2023-12-27T11:33:17.483939Z","shell.execute_reply.started":"2023-12-27T11:33:05.541338Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from glob import glob\n","import sys\n","import tifffile\n","import shutil\n","import numpy as np\n","from tqdm import tqdm\n","from torch.cuda.amp import autocast\n","import os\n","import segmentation_models_pytorch as smp\n","from torch.utils.data import Dataset, DataLoader\n","import gc"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:17.487395Z","iopub.status.busy":"2023-12-27T11:33:17.487076Z","iopub.status.idle":"2023-12-27T11:33:17.493745Z","shell.execute_reply":"2023-12-27T11:33:17.492854Z","shell.execute_reply.started":"2023-12-27T11:33:17.487366Z"},"trusted":true},"outputs":[],"source":["class cfg:\n","    # ============== model cfg =============\n","    in_chans = 6  # 65\n","    # ============== _ cfg =============\n","    image_size = 256\n","    stride = image_size // 1\n","    drop_egde_pixel = 32\n","    batch = 64\n","\n","    # ============== fold =============\n","    batch = 128\n","    model_path = [\"/kaggle/working/notebook/experiment/baseline/baseline/baseline_best_fold0.pth\"]\n","\n","\n","is_kaggle_notebook = \"kaggle_web_client\" in sys.modules\n","if is_kaggle_notebook:\n","    dir_test = \"/kaggle/input/blood-vessel-segmentation/test\"\n","else:\n","    dir_test = \"/kaggle/input/blood-vessel-segmentation/train/kidney_2\"\n","\n","dir_raw = \"/kaggle/working/dataset_test/stack_raw\"\n","dir_clipped = \"/kaggle/working/dataset_test/stack_clipped\""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def stack_tifs(dir_dataset, dir_stack):\n","    os.makedirs(dir_stack, exist_ok=True)\n","    for data_name in os.listdir(dir_dataset):\n","        for data_type in [\"images\", \"labels\"]:\n","            stack = []\n","            save_path = f\"{dir_stack}/{data_name}_{data_type}.npy\"\n","            tif_paths = glob(f\"{dir_dataset}/{data_name}/{data_type}/*.tif\")\n","\n","            if len(tif_paths) == 0:\n","                continue\n","            if os.path.exists(save_path):\n","                continue\n","\n","            for tif_path in sorted(tif_paths):\n","                tif = tifffile.imread(tif_path)\n","                stack.append(tif)\n","\n","            stack = np.stack(stack)\n","            np.save(save_path, stack)\n","\n","\n","# 訓練のためにpercentileに基づいて値をクリップしfloat32で保存\n","def save_clipped_npy(dir_raw, dir_clipped, percentile):\n","    os.makedirs(dir_clipped, exist_ok=True)\n","    for npy_path in glob(f\"{dir_raw}/*.npy\"):\n","        data_name = npy_path.split(\"/\")[-1].split(\".\")[0]\n","        data_type = data_name.split(\"_\")[-1]\n","        save_path = f\"{dir_clipped}/{data_name}.npy\"\n","\n","        if os.path.exists(save_path):\n","            continue\n","\n","        if \"voi\" in npy_path:\n","            continue\n","\n","        if \"labels\" == data_type:\n","            npy = np.load(npy_path).astype(bool)\n","\n","        elif data_type == \"images\":\n","            npy = np.load(npy_path)\n","            stack_len = npy.shape[0]\n","\n","            upper = stack_len * 0.3\n","            lower = stack_len * 0.7\n","\n","            p_low = int(np.percentile(npy[upper:lower], percentile))  # 上下端に近い部分はpercentile計算対象から除外\n","            p_high = int(np.percentile(npy[upper:lower], 100 - percentile))\n","\n","            npy = np.clip(npy, p_low, p_high).astype(\"float32\")\n","            scale = float(p_high - p_low)\n","            npy = (npy - p_low) / scale\n","\n","        np.save(save_path, npy)\n","\n","\n","stack_tifs(dir_test, dir_raw)\n","save_clipped_npy(dir_raw, dir_clipped, 0.05)\n","shutil.rmtree(dir_raw)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:17.495479Z","iopub.status.busy":"2023-12-27T11:33:17.495122Z","iopub.status.idle":"2023-12-27T11:33:17.511174Z","shell.execute_reply":"2023-12-27T11:33:17.510154Z","shell.execute_reply.started":"2023-12-27T11:33:17.495447Z"},"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, model_arch, backbone, in_chans, target_size, weight):\n","        super().__init__()\n","\n","        self.model = smp.create_model(\n","            model_arch,\n","            encoder_name=backbone,\n","            encoder_weights=weight,\n","            in_channels=in_chans,\n","            classes=target_size,\n","            activation=None,\n","        )\n","        self.batch = cfg.batch\n","        self.in_chans = in_chans\n","\n","    def forward_(self, image):\n","        output = self.model(image)\n","        return output[:, 0]\n","\n","    def forward(self, image):\n","        # image.shape=(batch,c,h,w)\n","        image = image.to(torch.float32)\n","\n","        shape = image.shape\n","        image = [torch.rot90(image, k=i, dims=(-2, -1)) for i in range(4)]\n","        image = torch.cat(image, dim=0)\n","        with autocast():\n","            with torch.no_grad():\n","                image = [self.forward_(image[i * self.batch : (i + 1) * self.batch]) for i in range(image.shape[0] // self.batch + 1)]\n","                image = torch.cat(image, dim=0)\n","        image = image.sigmoid()\n","        image = image.reshape(4, shape[0], *shape[2:])\n","        image = [torch.rot90(image[i], k=-i, dims=(-2, -1)) for i in range(4)]\n","        image = torch.stack(image, dim=0).mean(0)\n","\n","        return image\n","\n","\n","def load_model(model_path):\n","    pth = torch.load(model_path)\n","\n","    print(\"model_name\", pth[\"model_arch\"])\n","    print(\"backbone\", pth[\"backbone\"])\n","    model = CustomModel(pth[\"model_arch\"], pth[\"backbone\"], pth[\"in_chans\"], pth[\"target_size\"], weight=None)\n","    model.load_state_dict(pth[\"model\"])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","    return model\n","\n","\n","class InferenceDataset(Dataset):\n","    def __init__(self, stack, in_chan):\n","        self.in_chan = in_chan\n","\n","        pad = torch.zeros(self.in_chan // 2, *stack.shape[1:], dtype=stack.dtype)\n","        self.stack = torch.cat((pad, stack, pad), dim=0)\n","\n","    def __len__(self):\n","        return self.stack.shape[0] - self.in_chan\n","\n","    def __getitem__(self, z_):\n","        stack = self.stack[z_ : z_ + self.in_chan]\n","        return stack, z_"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:17.513522Z","iopub.status.busy":"2023-12-27T11:33:17.513262Z","iopub.status.idle":"2023-12-27T11:33:17.540545Z","shell.execute_reply":"2023-12-27T11:33:17.539595Z","shell.execute_reply.started":"2023-12-27T11:33:17.513499Z"},"trusted":true},"outputs":[],"source":["def add_pad(stack: torch.Tensor, pad: int):\n","    # stack=(C,H,W)\n","    # output=(C,H+2*pad,W+2*pad)\n","    mean_ = int(stack.to(torch.float32).mean())\n","    stack = torch.cat([stack, torch.ones([stack.shape[0], pad, stack.shape[2]], dtype=stack.dtype, device=stack.device) * mean_], dim=1)\n","    stack = torch.cat([stack, torch.ones([stack.shape[0], stack.shape[1], pad], dtype=stack.dtype, device=stack.device) * mean_], dim=2)\n","    stack = torch.cat([torch.ones([stack.shape[0], pad, stack.shape[2]], dtype=stack.dtype, device=stack.device) * mean_, stack], dim=1)\n","    stack = torch.cat([torch.ones([stack.shape[0], stack.shape[1], pad], dtype=stack.dtype, device=stack.device) * mean_, stack], dim=2)\n","    return stack\n","\n","\n","def shift_axis(tensor, axis):\n","    perm = [axis, (axis + 1) % 3, (axis + 2) % 3]  # 軸の順番をシフト\n","    tensor = tensor.permute(*perm)\n","    return tensor\n","\n","\n","def remove_pad(pred: torch.Tensor, pad: int):\n","    pred = pred[..., pad:-pad, pad:-pad]\n","    return pred\n","\n","\n","def cutout_chip(img, stack_shape, stride, img_size, edge):\n","    chip = []\n","    xy_indexs = []\n","\n","    x1_list = np.arange(0, stack_shape[-2] + 1, stride)\n","    y1_list = np.arange(0, stack_shape[-1] + 1, stride)\n","\n","    for y1 in y1_list:\n","        for x1 in x1_list:\n","            x2 = x1 + img_size\n","            y2 = y1 + img_size\n","            chip.append(img[..., x1:x2, y1:y2])\n","            xy_indexs.append([x1 + edge, x2 - edge, y1 + edge, y2 - edge])\n","    return chip, xy_indexs\n","\n","\n","def infer_each_z(model, img, stack_shape):\n","    img = img.to(\"cuda:0\")\n","    img = add_pad(img[0], cfg.image_size // 2)[None]\n","\n","    chip, xy_indexs = cutout_chip(img, stack_shape, cfg.stride, cfg.image_size, cfg.drop_egde_pixel)\n","\n","    preds = model.forward(torch.cat(chip)).to(device=0)\n","    preds = remove_pad(preds, cfg.drop_egde_pixel)\n","\n","    pred = torch.zeros_like(img[:, 0], dtype=torch.float32, device=img.device)\n","    count = torch.zeros_like(img[:, 0], dtype=torch.float32, device=img.device)\n","    for i, (x1, x2, y1, y2) in enumerate(xy_indexs):\n","        pred[..., x1:x2, y1:y2] += preds[i]\n","        count[..., x1:x2, y1:y2] += 1\n","    pred /= count\n","    pred = remove_pad(pred, cfg.image_size // 2)\n","\n","    pred = (pred[0] * 255).to(torch.uint8).cpu()\n","    return pred\n","\n","\n","def get_output(model, stack_path):\n","    os.makedirs(\"/kaggle/working/output\", exist_ok=True)\n","    kidney = stack_path.split(\"/\")[-1].split(\".\")[0]\n","\n","    for axis in [0, 1, 2]:\n","        stack = torch.tensor(np.load(stack_path))\n","        stack = shift_axis(stack, axis)\n","\n","        preds = torch.zeros_like(stack, dtype=torch.uint8)\n","\n","        dataset = InferenceDataset(stack, cfg.in_chans)\n","        dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n","        for img, z_ in tqdm(dataloader):  # img=(1,C,H,W)\n","            # if z_ == 400:\n","            #     break\n","            pred = infer_each_z(model, img, stack.shape)\n","            preds[z_] = pred\n","\n","        preds = shift_axis(preds, -axis)\n","        np.save(f\"/kaggle/working/output/{kidney}_{axis}.npy\", preds)\n","        del stack, preds, dataset, dataloader\n","        gc.collect()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T11:33:18.108202Z","iopub.status.busy":"2023-12-27T11:33:18.107531Z","iopub.status.idle":"2023-12-27T11:36:20.192303Z","shell.execute_reply":"2023-12-27T11:36:20.191145Z","shell.execute_reply.started":"2023-12-27T11:33:18.108167Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone efficientnet-b0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2217/2217 [02:53<00:00, 12.76it/s]\n","100%|██████████| 1041/1041 [02:26<00:00,  7.12it/s]\n","100%|██████████| 1511/1511 [03:17<00:00,  7.66it/s]\n"]}],"source":["model = load_model(cfg.model_path[0])\n","get_output(model, \"/kaggle/working/dataset/stack_clipped/kidney_2_images.npy\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["stack_path = \"/kaggle/working/dataset/stack_clipped/kidney_2_images.npy\"\n","stack = torch.tensor(np.load(stack_path))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = InferenceDataset(stack, cfg.in_chans)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def rle_encode(mask):\n","    pixel = mask.flatten()\n","    pixel = np.concatenate([[0], pixel, [0]])\n","    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n","    run[1::2] -= run[::2]\n","    rle = \" \".join(str(r) for r in run)\n","    if rle == \"\":\n","        rle = \"1 0\"\n","    return rle\n","\n","\n","def get_id(img_path):\n","    id = img_path.split(\"/\")[-3:]\n","    id.pop(1)\n","    id = \"_\".join(id)\n","    return id[:-4]\n","\n","\n","def get_ids(img_paths):\n","    ids = []\n","    for img_path in img_paths:\n","        ids.append(get_id(img_path))\n","    return ids\n","\n","\n","img_paths = sorted(glob(\"/kaggle/input/blood-vessel-segmentation/train/kidney_2/images/*.tif\"))\n","ids = get_ids(img_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["####################################\n","TH = [x.flatten().numpy() for x in outputs]\n","TH = np.concatenate(TH)\n","index = -int(len(TH) * cfg.th_percentile)\n","TH: int = np.partition(TH, index)[index]\n","print(TH)\n","\n","####################################\n","submission_df = []\n","debug_count = 0\n","for index in range(len(ids)):\n","    id = ids[index]\n","    i = 0\n","    for x in outputs:\n","        if index >= len(x):\n","            index -= len(x)\n","            i += 1\n","        else:\n","            break\n","    mask_pred = (outputs[i][index] > TH).numpy()\n","    ####################################\n","\n","    rle = rle_encode(mask_pred)\n","\n","    submission_df.append(\n","        pd.DataFrame(\n","            data={\n","                \"id\": id,\n","                \"rle\": rle,\n","            },\n","            index=[0],\n","        )\n","    )\n","\n","submission_df = pd.concat(submission_df)\n","submission_df.to_csv(\"submission.csv\", index=False)\n","submission_df.head(6)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":6962461,"sourceId":61446,"sourceType":"competition"},{"datasetId":4087873,"sourceId":7187369,"sourceType":"datasetVersion"},{"sourceId":150248402,"sourceType":"kernelVersion"},{"sourceId":156694315,"sourceType":"kernelVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
